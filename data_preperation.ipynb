{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Weekday vs Weekend Walking Distance Analysis**\n",
    "## **Data Preparation Notebook**\n",
    "\n",
    "This is the **first notebook** in the project.  \n",
    "Here, we will:\n",
    "1. Parse the XML file to extract walking distance data.\n",
    "2. Process the data for further analysis.\n",
    "3. Save the prepared data in a structured format (CSV).\n",
    "\n",
    "---\n",
    "\n",
    "### **Outputs**\n",
    "- A cleaned and processed dataset saved as `processed_walking_data.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "We need the following libraries for parsing and processing:\n",
    "1. `xml.etree.ElementTree`: To parse the XML file.\n",
    "2. `pandas`: To process and structure the extracted data.\n",
    "3. `os`: To check file existence and handle paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/egetas/Desktop/DSA210PROJECT\n",
      "Name: pandas\n",
      "Version: 2.0.3\n",
      "Summary: Powerful data structures for data analysis, time series, and statistics\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: The Pandas Development Team <pandas-dev@python.org>\n",
      "License: BSD 3-Clause License\n",
      "\n",
      "Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n",
      "All rights reserved.\n",
      "\n",
      "Copyright (c) 2011-2023, Open source contributors.\n",
      "\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "modification, are permitted provided that the following conditions are met:\n",
      "\n",
      "* Redistributions of source code must retain the above copyright notice, this\n",
      "  list of conditions and the following disclaimer.\n",
      "\n",
      "* Redistributions in binary form must reproduce the above copyright notice,\n",
      "  this list of conditions and the following disclaimer in the documentation\n",
      "  and/or other materials provided with the distribution.\n",
      "\n",
      "* Neither the name of the copyright holder nor the names of its\n",
      "  contributors may be used to endorse or promote products derived from\n",
      "  this software without specific prior written permission.\n",
      "\n",
      "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
      "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
      "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
      "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
      "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
      "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
      "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "\n",
      "Location: /Users/egetas/anaconda3/lib/python3.11/site-packages\n",
      "Requires: numpy, numpy, python-dateutil, pytz, tzdata\n",
      "Required-by: bokeh, datasets, datashader, holoviews, hvplot, panel, seaborn, statsmodels, xarray\n",
      "Name: numpy\n",
      "Version: 1.24.3\n",
      "Summary: Fundamental package for array computing in Python\n",
      "Home-page: https://www.numpy.org\n",
      "Author: Travis E. Oliphant et al.\n",
      "Author-email: \n",
      "License: BSD-3-Clause\n",
      "Location: /Users/egetas/anaconda3/lib/python3.11/site-packages\n",
      "Requires: \n",
      "Required-by: astropy, bokeh, Bottleneck, contourpy, datasets, datashader, datashape, gensim, h5py, holoviews, hvplot, imagecodecs, imageio, imbalanced-learn, matplotlib, numba, numexpr, pandas, patsy, pyarrow, pyerfa, PyWavelets, scikit-image, scikit-learn, scipy, seaborn, statsmodels, tables, tifffile, transformers, xarray\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Check current working directory\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "!pip show pandas\n",
    "!pip show numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying File Existence\n",
    "We will verify whether the `export.xml` file is in the expected location.  \n",
    "If the file is not found, an appropriate message will be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found at: export.xml\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path for the XML file\n",
    "file_path = 'export.xml' \n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"File not found at: {file_path}. Please check the path.\")\n",
    "else:\n",
    "    print(f\"File found at: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the XML File\n",
    "Using `ElementTree`, we will parse the XML file to explore its structure and prepare for data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root tag: HealthData\n",
      "Attributes: {'locale': 'en_AU@rg=trzzzz'}\n"
     ]
    }
   ],
   "source": [
    "# Parse the XML file and extract data\n",
    "tree = ET.parse(file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "\n",
    "print(\"Root tag:\", root.tag)\n",
    "print(\"Attributes:\", root.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Walking Distance Data\n",
    "From the XML file, we will extract:\n",
    "- `Date`: The start date of the activity.\n",
    "- `WalkingDistance_km`: The walking distance recorded for that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data:\n",
      "         Date  WalkingDistance_km\n",
      "0  2019-10-28             0.02648\n",
      "1  2019-10-28             0.00547\n",
      "2  2019-11-29             0.09277\n",
      "3  2019-11-29             0.05989\n",
      "4  2019-11-29             0.07366\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store records\n",
    "data = []\n",
    "\n",
    "# Loop through the XML to extract walking distance data\n",
    "for record in root.findall('.//Record'):\n",
    "    if record.get('type') == 'HKQuantityTypeIdentifierDistanceWalkingRunning':\n",
    "        # Extract relevant information\n",
    "        date = record.get('startDate').split(' ')[0]  # Extract the date\n",
    "        distance = float(record.get('value'))  # Extract the distance\n",
    "        \n",
    "        # Append to the data list\n",
    "        data.append({'Date': date, 'WalkingDistance_km': distance})\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"Sample Data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Data\n",
    "We will enhance the dataset by:\n",
    "1. Converting `Date` to a proper datetime format.\n",
    "2. Adding a `Weekday` column to represent the day of the week.\n",
    "3. Adding an `IsWeekend` column to indicate weekends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Data:\n",
      "        Date  WalkingDistance_km  Weekday  IsWeekend\n",
      "0 2019-10-28             0.02648        0      False\n",
      "1 2019-10-28             0.00547        0      False\n",
      "2 2019-11-29             0.09277        4      False\n",
      "3 2019-11-29             0.05989        4      False\n",
      "4 2019-11-29             0.07366        4      False\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Add a column for the day of the week (0 = Monday, 6 = Sunday)\n",
    "df['Weekday'] = df['Date'].dt.dayofweek\n",
    "\n",
    "# Add a column to indicate weekends (True for Saturday and Sunday)\n",
    "df['IsWeekend'] = df['Weekday'].apply(lambda x: x >= 5)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"Processed Data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data\n",
    "Here, we perform a quick exploration of the dataset:\n",
    "1. Basic summary statistics for walking distances.\n",
    "2. The range of dates covered in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "count    68691.000000\n",
      "mean         0.116509\n",
      "std          0.147725\n",
      "min          0.000410\n",
      "25%          0.018320\n",
      "50%          0.055670\n",
      "75%          0.155215\n",
      "max          1.247270\n",
      "Name: WalkingDistance_km, dtype: float64\n",
      "\n",
      "Date Range:\n",
      "Start Date: 2019-10-28 00:00:00, End Date: 2025-01-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics of the walking distance\n",
    "print(\"Summary Statistics:\")\n",
    "print(df['WalkingDistance_km'].describe())\n",
    "\n",
    "# Check the range of dates in the dataset\n",
    "print(\"\\nDate Range:\")\n",
    "print(f\"Start Date: {df['Date'].min()}, End Date: {df['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Processed Data\n",
    "We will save the cleaned and processed data as a CSV file for use in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: processed_walking_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the processed data to a CSV file for further analysis\n",
    "output_file = 'processed_walking_data.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed data saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
